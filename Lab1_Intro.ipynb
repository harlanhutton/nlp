{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1_Intro.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LuHfrDrQyiE1",
        "hHAxRnEd01GJ"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harlanhutton/nlp/blob/main/Lab1_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bJ5MYO355hH"
      },
      "source": [
        "# Welcome to the first lab!\n",
        "\n",
        "This lab is a refresher of Python, Pytorch, Numpy and the Colab infrasrtucture which we are going to use during this class.\n",
        "\n",
        "The rule of thumb #1: try to understand every single line of code in the lab notebook.\n",
        "\n",
        "The rule of thumb #2: do not hesitate to ask a question about any line of code, this is precisely why we do these labs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6OZX4W26gPV"
      },
      "source": [
        "## Google Colab\n",
        "\n",
        "https://research.google.com/colaboratory/faq.html\n",
        "\n",
        "Main things to remember:\n",
        "\n",
        "* It is free to use;\n",
        "\n",
        "* Colab resources **are not guaranteed** and not unlimited, and the usage limits sometimes fluctuate;\n",
        "\n",
        "* Colab notebooks are stored in Google Drive, or can be loaded from GitHub. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMEvCuWQ5plp",
        "outputId": "5382a6c5-9c62-48ef-c8a9-e0e1daa306a1"
      },
      "source": [
        "# Colab is effectively running on the Linux virtual machine in the cloud\n",
        "# exclamation mark will pass the command to the tty/terminal\n",
        "\n",
        "! uname -a "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux d1544c3d40bd 5.4.104+ #1 SMP Sat Jun 5 09:50:34 PDT 2021 x86_64 x86_64 x86_64 GNU/Linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFd1NHIN7kbL",
        "outputId": "e878a42b-2795-4781-b3e1-79b0559b5436"
      },
      "source": [
        "# Colab gives you the write access to some part of the virtual file system\n",
        "\n",
        "! pwd\n",
        "! echo 'file on colab' > test.txt\n",
        "! ls -lh\n",
        "! cat test.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "total 8.0K\n",
            "drwxr-xr-x 1 root root 4.0K Aug 25 13:35 sample_data\n",
            "-rw-r--r-- 1 root root   14 Aug 31 21:27 test.txt\n",
            "file on colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOw1mMSt8IFc"
      },
      "source": [
        "### Data munging: local filesystem / google drive / direct download from the internet\n",
        "\n",
        "more details here: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=vz-jH8T_Uk2c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "SicIhDOi8qcy",
        "outputId": "ca1b42f7-4d22-43a7-ea20-bb670681b2b8"
      },
      "source": [
        "# uploading from your local filesystem\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e13ff6d4-2ce6-4c32-ac89-f515bd3b4bfa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e13ff6d4-2ce6-4c32-ac89-f515bd3b4bfa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ba06c3476cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "islbSgZZ72VX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFCa9qGy-f9v"
      },
      "source": [
        "## Installing exernal packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHyvoo5Q-imo"
      },
      "source": [
        "# list currently installed packages\n",
        "\n",
        "! pip list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERvIL_mp-rCn",
        "outputId": "8154cd8f-4bcb-4bb3-c0f0-b2601d277162"
      },
      "source": [
        "# installing nlp library\n",
        "\n",
        "! pip install datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 41.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting huggingface-hub<0.1.0\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Collecting fsspec>=2021.05.0\n",
            "  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, huggingface-hub, fsspec, datasets\n",
            "Successfully installed datasets-1.11.0 fsspec-2021.8.1 huggingface-hub-0.0.16 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ4bKo_ZpHHY"
      },
      "source": [
        "## Python\n",
        "\n",
        "Python refresher material is adapted from https://colab.research.google.com/drive/1pfIa4Mfynjsi7F38P8J6lF1qaGlolzzw\n",
        "\n",
        "For this lab and much of machine learning, we will use Python for its ease of understanding and large library ecosystem. Let's briefly go over Python syntax and features.\n",
        "\n",
        "Python is an [imperative language](https://en.wikipedia.org/wiki/Imperative_programming) based on [statements](https://en.wikipedia.org/wiki/Statement_(computer_science)). That is, programs in Python consists of lines composed of statements. Among other things, a statement can be:\n",
        "* a single expression, e.g. `5 + 5`\n",
        "* an assignment, e.g. `x = 5`\n",
        "    * variable names can be any length and can consist of uppercase and lowercase letters (A-Z, a-z), digits (0-9), and the underscore character (_), except they cannot start with a digit\n",
        "* a function call, e.g. `print(x)`\n",
        "* make in-line comments by prepending lines with \\#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lAwIxV5qF_O"
      },
      "source": [
        "### Built-in Data Types\n",
        "\n",
        "* Numbers: there are two important numerical types, `int` and `float`\n",
        "  * integers: `1`, `-3`, etc.\n",
        "  * floating-point: `1.0`, `3.14`, etc.\n",
        "* strings: `'apple'`, `\"v\"`\n",
        "* boolean values: `True`, `False`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEu4JTHnrpDG"
      },
      "source": [
        "### Functions\n",
        "\n",
        "Functions are defined with the following syntax:\n",
        "```\n",
        "def function_name(arg1, args2=default2, ...):\n",
        "    # function body\n",
        "    return\n",
        "```\n",
        "Most of the time, your functions should return a value (possibly multiple values, separated by commas) using the `return` keyword, but this isn't a requirement. If you don't explicitly return something, the function will return the special `None` value by default.\n",
        "\n",
        "Functions are called by using the function name followed by parentheses.\n",
        "If you use the function name without parentheses, you are referring to the function itself, as an object.\n",
        "\n",
        "Python contains many built-in functions. Some of these are straightforward math operators, (e.g. `+, -, /, *`), and others must be called using parentheses, such as `print()`, `int()`, `sum()`, or `len()`.\n",
        "\n",
        "**(exercise)** Write a function that takes in two numbers and computes their mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nri12FTCpaNp"
      },
      "source": [
        "def mean(a, b):\n",
        "    # TODO\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNzrTRQZIdtw"
      },
      "source": [
        "mean(1,6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1hQYVS-rGL0"
      },
      "source": [
        "### Data Structures\n",
        "\n",
        "Python also has three built-in data structures that are very useful:\n",
        "\n",
        "**Lists** are ordered lists and are created using brackets (`[]`) with comma-separated values. We can access list elements using the list name followed by the index of the element we want to access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7rFwFL0rM8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acaded17-4b5c-4369-d9b6-081d715ce0ed"
      },
      "source": [
        "# lists\n",
        "l = [1, 2, 3]\n",
        "print(l[0]) # indexing\n",
        "print(l[1])\n",
        "print(l[-1]) # negative indexing\n",
        "print(l[:2]) # slicing\n",
        "\n",
        "ll = [1, \"a\", []] # list elements don't need to be the same type\n",
        "\n",
        "lll = [] # defining empty list, also `list()`\n",
        "print(lll)\n",
        "lll.append(1) # add to a list\n",
        "lll.append(2)\n",
        "print(lll)\n",
        "print(len(lll)) # get the length\n",
        "\n",
        "print(ll + lll) # concatenation of two lists"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "[1, 2]\n",
            "[]\n",
            "[1, 2]\n",
            "2\n",
            "[1, 'a', [], 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVydmiCqkmO"
      },
      "source": [
        "**Dictionaries**, or hash tables, are sets of key-value pairs. We create dictionaries using curly braces (`{}`). We can access the value associated with a particular key by typing the name of the dictionary followed by the key in brackets. The key can be a variable or a literal (strings or numbers).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eV4PAYzriWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e82c589-a11c-499c-e91d-6805ab35180c"
      },
      "source": [
        "d = {\"apple\": \"a fruit\", \"banana\": \"an herb\", \"monkey\": \"a mammal\"}\n",
        "print(len(d)) # number of key-value pairs in d\n",
        "print(d[\"apple\"]) # accessing an element\n",
        "\n",
        "d['broccoli'] = 'a vegetable' # assign a new key-value pair\n",
        "del d['apple'] # delete a key-value pair\n",
        "print(\"apple\" in d) # check membership\n",
        "key = \"banana\"\n",
        "print(key in d) # variables as keys\n",
        "\n",
        "print(d.keys()) # unordered list of keys in the dictionary\n",
        "print(d.values()) # unordered list of values in the dictionary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "a fruit\n",
            "False\n",
            "True\n",
            "dict_keys(['banana', 'monkey', 'broccoli'])\n",
            "dict_values(['an herb', 'a mammal', 'a vegetable'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZVcUoCQqmDh"
      },
      "source": [
        "**Tuples** are also ordered lists of items, but unlike lists they cannot be changed (i.e., they're immutable). Tuples are created using parentheses and their elements can also be accessed using brackets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7mzqXoGreG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3cfdabe-0a81-4191-da32-286f331d5eec"
      },
      "source": [
        "t = (1, 2, \"cow\")\n",
        "print(t[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2vXBv65_lyH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95SfLBiTnb9u"
      },
      "source": [
        "# PyTorch\n",
        "\n",
        "The material in this section is borrowed from [here](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "\n",
        "**What is PyTorch?**\n",
        "\n",
        "PyTorch is a Python-based scientific computing package serving two broad purposes:\n",
        "* A replacement for NumPy to use the power of GPUs and other accelerators.\n",
        "* An automatic differentiation library that is useful to implement neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDl9sXELx3XQ"
      },
      "source": [
        "## Tensors\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other specialized hardware to accelerate computing. If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along in this quick API walkthrough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cufYkqoix_lT"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrG3ItA8yARk"
      },
      "source": [
        "### Tensor Initialization\n",
        "\n",
        "Tensors can be initialized in various ways. Take a look at the following examples:\n",
        "\n",
        "**Directly from data**\n",
        "\n",
        "Tensors can be created directly from data. The data type is automatically inferred."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBkIzWteyJqn"
      },
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74cRi34UJ6BF",
        "outputId": "1d6c02fe-0160-4999-db45-cfef28458a98"
      },
      "source": [
        "x_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqozxiGjyKqv"
      },
      "source": [
        "**From a NumPy array**\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQX68gs6yTLF"
      },
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGz7Ex5wyWt8"
      },
      "source": [
        "**From another tensor:**\n",
        "\n",
        "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOh5LkoqyZ5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01edbeaa-9b70-4a9d-e388-0bbd47a62bcc"
      },
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.5667, 0.5738],\n",
            "        [0.0545, 0.7615]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bHbzKH2ycCM"
      },
      "source": [
        "**With random or constant values:**\n",
        "\n",
        "shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuHfrDrQyiE1"
      },
      "source": [
        "### Tensor Attributes\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on which they are stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5wNEGQ8ylDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10405454-e2f5-4a57-b6a1-59977f28d243"
      },
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3R783B6ylzM"
      },
      "source": [
        "### Tensor Operations\n",
        "\n",
        "Over 100 tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random sampling, and more are comprehensively described here: https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "Most of them can be run on the GPU (at typically higher speeds than on a CPU). If you’re using Colab, allocate a GPU by going to **Runtime -> Change runtime type.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vERXB6n0yqYJ"
      },
      "source": [
        "# We move our tensor to the GPU if available\n",
        "import torch\n",
        "tensor = torch.rand(3,4)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xucuo8iLNO82",
        "outputId": "c9844aef-a696-4815-8403-845fc3dd1e25"
      },
      "source": [
        "tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3972, 0.4806, 0.9385, 0.0626],\n",
              "        [0.1392, 0.1758, 0.0638, 0.2027],\n",
              "        [0.6743, 0.4054, 0.5922, 0.8431]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFbl5lUHyrDM"
      },
      "source": [
        "Try out some of the operations from the list. If you’re familiar with the NumPy API, you’ll find the Tensor API a breeze to use.\n",
        "\n",
        "**Standard numpy-like indexing and slicing:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etlzxjJuywV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff53ed84-75d9-4d0d-e89a-377e061f7d76"
      },
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peBOM6_Wyw0v"
      },
      "source": [
        "**Joining tensors** You can use torch.cat to concatenate a sequence of tensors along a given dimension. See also torch.stack, another tensor joining op that is subtly different from torch.cat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnM7q14Fy1OP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57c297c-d363-4bf3-dcb7-80856a1c48c8"
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7cHyirby4EP"
      },
      "source": [
        "**Multiplying tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxqQjiehy7Df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d1b4c4-7a46-487c-d2fe-f7492ef48a1f"
      },
      "source": [
        "# This computes the element-wise product\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.mul(tensor) \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC5CT5Xmy74m"
      },
      "source": [
        "This computes the matrix multiplication between two tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czIxXEJmy_oa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399f1f86-4a8c-45b4-8fd9-a59aceb9d8a8"
      },
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yolxt60MzGYC"
      },
      "source": [
        "**In-place operations** Operations that have a _ suffix are in-place. For example: x.copy_(y), x.t_(), will change x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nZcFQggzJ-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3504b0f2-a823-4369-97f9-f9b819dbb00a"
      },
      "source": [
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koi1gE0zXkLC"
      },
      "source": [
        "**Broadcasting** This term means specific set of rules which allows to make operations with two tensors when their shapes do not match directly. We encourage students to read more about broadcasting rules and shape manipulations if they feel lack of experience with this topic.\n",
        "\n",
        "Useful references: \n",
        "https://machinelearningknowledge.ai/pytorch-tutorial-for-reshape-squeeze-unsqueeze-flatten-and-view/\n",
        "\n",
        "https://medium.com/ai%C2%B3-theory-practice-business/broadcasting-in-pytorch-numpy-36bbdef22dff\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XFOcUFsXjOz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMLDsc9ozO1R"
      },
      "source": [
        "### Bridge with NumPy\n",
        "\n",
        "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other.\n",
        "\n",
        "### Tensor to NumPy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kErWZIOfzVsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d807541-05df-4faf-c440-ec34d832e8f7"
      },
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SK-BA-hzXwr"
      },
      "source": [
        "A change in the tensor reflects in the NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l8EgmHgzaV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de671cbb-1b38-4b4d-883f-61122ba63ec4"
      },
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOqQlG55zcGH"
      },
      "source": [
        "NumPy array to Tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTJD_1fVzem_"
      },
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMtuursEzgPs"
      },
      "source": [
        "Changes in the NumPy array reflects in the tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaK015BzzjXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57968526-e8fc-4b1e-8589-679883d2bc2f"
      },
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkWeE9uAB74h"
      },
      "source": [
        "## Models in PyTorch\n",
        "\n",
        "PyTorch provides a submodule for implementing and building machine learning models called `torch.nn` (`nn` for neural networks). `nn` implements many common mathematical transformations as functions that can be chained together to build machine learning modules. Let's go over an example of creating and using logistic regression in PyTorch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf0USHtgB66y",
        "outputId": "bc126808-fae0-4067-fd5d-44a0b21b19a9"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BinaryLogisticRegression(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "    super(BinaryLogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(input_dim, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, input):\n",
        "    outputs = self.sigmoid(self.linear(input)) # includes the bias term\n",
        "    return outputs\n",
        "\n",
        "model = BinaryLogisticRegression(2) # instantiate model, this will implicitly initialize the parameters following default initialization scheme\n",
        "print(f\"Model: {model}\")\n",
        "print(f\"Linear weights:\\n {model.linear.weight}\")\n",
        "print(f\"Linear bias:\\n {model.linear.bias}\")\n",
        "print()\n",
        "print(f\"Dummy model outputs: {model(torch.rand(2))}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: BinaryLogisticRegression(\n",
            "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "Linear weights:\n",
            " Parameter containing:\n",
            "tensor([[-0.2047,  0.4436]], requires_grad=True)\n",
            "Linear bias:\n",
            " Parameter containing:\n",
            "tensor([-0.4137], requires_grad=True)\n",
            "\n",
            "Dummy model outputs: tensor([0.3853], grad_fn=<SigmoidBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q_v5N-6znrr"
      },
      "source": [
        "## A Gentle Introduction To `torch.autograd`\n",
        "\n",
        "`torch.autograd` is PyTorch’s automatic differentiation engine that powers neural network training. In this section, you will get a conceptual understanding of how autograd helps a neural network train.\n",
        "\n",
        "### Background\n",
        "\n",
        "Neural networks (NNs) are a collection of nested functions that are executed on some input data. These functions are defined by parameters (consisting of weights and biases), which in PyTorch are stored in tensors.\n",
        "\n",
        "Training a NN happens in two steps:\n",
        "\n",
        "**Forward Propagation:** In forward prop, the NN makes its best guess about the correct output. It runs the input data through each of its functions to make this guess.\n",
        "\n",
        "**Backward Propagation:** In backprop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collecting the derivatives of the error with respect to the parameters of the functions (gradients), and optimizing the parameters using gradient descent. For a more detailed walkthrough of backprop, [check out this video from 3Blue1Brown](https://www.youtube.com/watch?v=tIeHLnjs5U8)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHAxRnEd01GJ"
      },
      "source": [
        "### Differentiation in Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8hxDwYJ02vi"
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(6., requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtt0San-04cf"
      },
      "source": [
        "We create another tensor Q from a and b.\n",
        "\n",
        "$Q=3a^{3} - b^{2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG-9-MgE1B5X"
      },
      "source": [
        "Q = 3*a**3 - b**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWBl1eNU1CXj"
      },
      "source": [
        "Let’s assume a and b to be parameters of an NN, and Q to be the error. In NN training, we want gradients of the error w.r.t. parameters, i.e.\n",
        "\n",
        "$\\frac{\\partial Q}{\\partial a} = 9a^{2}$\n",
        "\n",
        "$\\frac{\\partial Q}{\\partial b} = -2b$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ7kMPii1gcd"
      },
      "source": [
        "When we call .backward() on Q, autograd calculates these gradients and stores them in the respective tensors’ .grad attribute.\n",
        "\n",
        "We need to explicitly pass a gradient argument in Q.backward() because it is a vector. gradient is a tensor of the same shape as Q, and it represents the gradient of Q w.r.t. itself, i.e.\n",
        "\n",
        "$\\frac{\\partial Q}{\\partial Q} = 1$\n",
        "\n",
        "Equivalently, we can also aggregate Q into a scalar and call backward implicitly, like Q.sum().backward().\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7SVrSFz1r8H"
      },
      "source": [
        "Q.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUx2vXcS1uPG"
      },
      "source": [
        "Gradients are now deposited in a.grad and b.grad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqTMDgjU1vz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113e9b45-a51a-480d-abc8-504b3658d623"
      },
      "source": [
        "# check if collected gradients are correct\n",
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(True)\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp8aY1QhFtdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd56bed-0099-483c-e344-864a8a3e6d03"
      },
      "source": [
        "a.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(36.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU-C5Y6tDUgD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}